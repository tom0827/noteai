In the second part of the lecture, we'll look at earthquake prediction, forecasting, early warning and rapid response. We'll start with a brief look back at the four pillars of emergency management. We covered mitigation in the first video. One of the issues that was raised is that mitigating earthquake damage costs a lot of money, particularly when older buildings have to be retrofitted. Therefore, it is critical that we spend our money wisely, targeted at the places that most need it. This is where earthquake prediction and earthquake forecasting come in, our first two topics of this video. These count towards earthquake preparedness, which is preparing to handle the emergency before it happens. Later, we'll discuss earthquake early warning and other types of earthquake response. Earthquake predictions specify the location, timing and magnitude of a future shock. A successful prediction must pass statistical tests to show that it improved upon random chance. It would be easy for me to predict that there will be an earthquake somewhere in California tomorrow, but there are dozens of recorded earthquakes in California every day, so my prediction does not improve upon random chance. Furthermore, what is the value of my prediction without specifying the location within California, the magnitude of the event and the specific timing? Without this information, the prediction is useless. Earthquake predictions rely upon precursors events that are supposed to occur just before the main earthquake strikes. Proposed earthquake precursors include foreshocks, electrical or magnetic disturbances and strange animal behaviors. In 1975, the Chinese city of Haicheng, which at that time had a population of around 1 million, was evacuated the day before a magnitude 7.3 earthquake. The prediction was made following intense foreshock activity, as well as reports of strange animal behavior and changes in groundwater levels. 2,000 people were still killed by the earthquake, but the death toll would have been much higher without the prediction and subsequent evacuation. This is often held up as an example of a successful prediction. However, evacuations had been ordered before, but had proven false alarms. Even worse, a year later in 1976, a larger magnitude 7.6 earthquake struck the nearby city of Tangshan. In this case, there were no foreshocks, no prediction was made, no evacuation was ordered, and 250,000 people were killed. So was the 1975 prediction truly a successful one? I would argue that it was not. Recall from earlier in the course that only about 5% of large earthquakes have foreshocks, and what's more, these foreshocks look no different from random small earthquakes that happen all of the time. We learn through the example of the 2019 Ridgecrest earthquake sequence how foreshocks can only be identified as foreshocks once the larger main shock has occurred. Other types of proposed precursor signals are even less reliable than foreshocks. None have passed any kind of rigorous statistical test, and even worse, most have absolutely no physical basis. For these reasons, we are still a million miles from being able to predict earthquakes. Earthquake forecasting is distinct from earthquake prediction, and in contrast, is an important and effective tool in preparing for earthquakes. Forecasting means assessing the general probability of an earthquake, of a given magnitude, in a given area, and over a specified length of time, but usually a long interval like 50 years. The image here illustrates a state-of-the-art earthquake forecast for the state of California. The small coloured polygons show mapped active faults, coloured according to the estimated 30-year likelihood of them hosting an earthquake greater than magnitude 6.7. Faults marked by red polygons, like the San Andreas fault, are forecast to have around a 10% chance of rupturing in a magnitude 6.7 plus earthquake during the next 30 years. Orange polygons have about a 1% chance, and green polygons have about a 0.1% chance. Earthquake forecasts are constructed from a number of important datasets. Firstly, they ideally require the locations of active faults to be known. These can be mapped from the surface geology, using remote sensing techniques such as LiDAR, or from trends in seismicity. Fault mapping is important not only for knowing where earthquakes might occur, but also what magnitudes these events could reach, since earthquake magnitude depends on rupture area, which is limited by the available fault surface area. For the same reason, it's also crucial to know how deep the brittle faults extend, and whether neighbouring faults might be connected at depth, which could allow the rupture to cross between them. Secondly, forecasts would ideally incorporate knowledge of the rates of strain accumulation on those faults, measured using networks of GPS stations. This strain accumulation must eventually be released in earthquakes, and so it sets the average tempo of future earthquake activity. Thirdly, forecasts may benefit from knowledge of earthquake recurrence intervals, estimated from paleoseismology, meaning the study of old earthquakes. Recurrence intervals for surface rupture in crustal faults can be estimated by digging a trench across the fault to reveal offsets to sedimentary layers generated in past earthquakes, and dating the sediments using geochronology. For subduction megathrust faults, tsunami deposits were often used, as we saw with the 2011 Tohoku earthquake in a previous lecture. Here in Cascadia, estimates of the 50-year probability of a magnitude 8 to 9 megathrust earthquake range from about 12%, or 1 in 8, to about 33%, or 1 in 3. These forecasts are based, firstly, on the fact that the Cascadia megathrust fault location, length, and subsurface geometry are known from geophysical studies. Secondly, the forecast relies upon knowledge of strain accumulation rates from GPS sensors. These show that the megathrust fault is being loaded at about 4 cm per year. This strain must eventually be released in earthquakes. Thirdly, the forecasts take into account estimated ages of prehistoric earthquakes. The last major rupture of the Cascadian megathrust was in 1700 CE, but we can extend the record back much further using paleoseismology. The best paleoseismic record for the Cascadian megathrust has been established through coring of offshore turbidite deposits. Turbidites are rapid, downslope movements of sediment-laden water that occur around the margins of continents. Turbidite cores have been gathered from offshore northern California, offshore Oregon, and offshore Washington at the locations marked by circles on this map. Through dating of the material in the cores, it is shown that many of the turbidite deposits correlate in age, consistent with them sharing the same trigger, most plausibly a very large earthquake on the underlying megathrust fault. From this work, we know that in the past 7,200 years, there have been around 13 such earthquakes. The timing of 7,200 years is from a prominent ash layer erupted from Mount Hazana, the same eruption that created Oregon's Crater Lake, which some of you may have visited. The average recurrence interval is therefore 7,200 years divided by 13, about 500 years. However, the paleoseismic record also shows that many of these earthquakes cluster in time, such that the inter-seismic intervals between earthquakes are anywhere from as short as 200 years to as long as 1,000 years. It therefore means rather little that the last earthquake was 320 years ago. The next one could be tomorrow, or it could be in 600 years. In many parts of the world, the data needed to produce a sophisticated earthquake forecast are simply lacking. Unfortunately, this is true of most of Canada. Away from the main plate boundary faults offshore British Columbia, the Cascadia megathrust and the Queen Charlotte transform fault, we have little idea as to where all of the active faults are located, let alone any knowledge about their paleoseismic records or how rapidly they accumulate tectonic strain. In these instances, it is still useful to estimate the hazard qualitatively using whatever data we do have to hand. The National Seismic Hazard Map for Canada is an example. Away from Cascadia, there is no probabilistic forecast for earthquakes in a given area or on a given fault, but the relative likelihood of large earthquakes in different regions of the country are known quite well. Earthquake hazard maps are also useful on local scales. This shows a seismic hazard map for Victoria. The different levels of hazard shown here are not based on different likelihoods of earthquakes since any larger nearby earthquake will impact the entire city. Instead, the different hazard levels are based on the surface geology, taking into account factors like basin amplification and liquefaction. If you ever buy property here in Victoria, or even choose a place to live, it is well worth your time looking up the latest iteration of this map, which is available on the BC Government website. Next, we'll look in a little more detail at earthquake early warning. An earthquake early warning is not the same as an earthquake prediction, since the early warning is only issued after the earthquake rupture has started. This slide illustrates how earthquake early warning systems work by detecting and locating earthquakes within a few seconds of their initiation, normally using the fastest travelling P waves, and then warning people in nearby cities before the slower, damaging shear waves and surface waves reach them. The amount of warning depends not only on how quickly the earthquake can be characterised, but also how close the fault is to the city. It is not possible to provide any early warning for an earthquake that occurs directly underneath a city. Earthquake early warning systems rely upon large investments in infrastructure. Firstly, the causative fault must be surrounded by seismic stations so that the earthquake can be quickly detected. Secondly, reliable automated algorithms are needed to locate the earthquake and estimate its magnitude. The latter is crucial because you don't want to issue warnings for small events that produce any slight or moderate ground shaking. Otherwise people will soon stop taking the alerts seriously. Thirdly, the early warning relies on a sophisticated system of communication and response. Online apps or public sirens can be triggered, heavy machinery can be safely switched off, and trains can be brought to a halt before the strong shaking starts. The following video shows footage of a successful early warning of the 2017 magnitude 7.1 Puebla earthquake in Mexico City. By coincidence, this earthquake happened on the same date, the 19th of September, as the magnitude 8.0 Michoac√°n earthquake 32 years earlier in 1985. This is the reason that the large Mexican flag in the center of the square is at half-mast. In fact, Mexicans do an earthquake drill each year on this very date. The office workers seen pouring out of the buildings at the sounding of the alarm had completed an earthquake drill just two hours previously. Here you can see the shaking start. Here in British Columbia, emerging early warning systems focus mostly on the Cascadia megathrust vault. This presents some challenges since the locked part of the Cascadia megathrust is mostly offshore. Ocean Networks Canada, a spinoff from UVic, have been contracted by the BC government to develop the province's first earthquake early warning system over the coming few years. A core part of the physical infrastructure will be the Neptune cabled observatory that includes seismometers, pressure gauges, and other instruments placed across the northern Cascadia megathrust. These are linked by fiber optic cable to a data center in Port Alberni, so that if the megathrust vault starts to slip, a warning can quickly be issued. Note, however, that this system would be little help in providing early warnings for earthquakes within the fore arc or within the down-going Juan de Fuca slab. Earthquake preparedness also includes education campaigns and earthquake drills. All of us should know what to do in an earthquake, drop, cover, and hold on, and prepare an earthquake emergency kit and a grab-and-go bag at home. There are some good online resources at PreparedBC that explain what should go into your kits. You can also practice your earthquake drill by signing up for the ShakeOut exercise, which occurs each October. In the last part of the lecture, we'll consider earthquake response, responding safely to the emergency once it happens. In particular, I will stress the importance of rapid response. Most people who die in earthquakes do so because buildings collapse. If you're not killed by falling rubble, you may well get trapped by it. It is very unusual for anyone to survive more than three days trapped in this way, unless they are very lucky and they are uninjured and can reach a supply of water. Therefore, it is imperative to assess building damage quickly so that search and rescue teams can be sent to the places they are most needed. Unfortunately, after the most devastating earthquakes, the worst affected areas are left in disarray, often without any outside communications. Therefore, critical information from the worst hit regions is often slow in getting out, undermining the important decisions that governments and first responders have to make. One emerging way to provide this critical information more accurately and quickly is using computer algorithms that can estimate the likely distribution of damage in a matter of minutes. I'd like you to consider this question. If you wanted to map out the human impacts of an earthquake that had just occurred, what scientific information would be most important? You can pause the video and jot down some information that you think would be useful. Here is my attempt at this question. Firstly, we'd like to know what kind of shaking people experienced. The earthquake location, magnitude, and depth are all obviously critical. Surface waves attenuate with increasing distance, so the shaking is likely to be greatest, closest to the causative fault. Larger and shallower earthquakes will normally produce stronger ground shaking than smaller and deeper earthquakes. The epicenter, magnitude, and depth can usually be determined with reasonable accuracy within a few minutes of the earthquake itself in any part of the world. So this is not a rate-limiting step. Ideally, we'd like to know the distribution of ground shaking or intensities. We might get some of this information very quickly from instrumental accelerometers. Felt reports might take a few hours to come in for online questionnaires such as the USGS Did You Feel It? website, or longer still if collected the traditional way. Even if intensity measurements are unavailable, we can estimate the distribution of intensities by combining knowledge of the earthquake with information about the region or geology. For example, taking into account things like basin amplification or susceptibility to liquefaction. This is information that we can gather ahead of time. The question though asks not for the distribution of intensities, but that of human impacts. Therefore, we need information on the population exposed to different levels of shaking, the type of dwellings that they live in, and the safety standard that these homes were built to. Again, this is information that we can collate ahead of time. Lastly, the time of day and even the day of the week can affect the impacts of an earthquake. In rural areas, many people are outside during the day, and so daytime earthquakes are typically less deadly than nighttime earthquakes. In cities, many victims are injured or killed by falling debris, and so the night might be the better time for an earthquake as streets will have emptied. Whether the earthquake occurred during a weekday or at a weekend can be important for similar reasons. In summary, there is a lot of information available by which we could quickly estimate the distribution of human impacts from an earthquake. The USGS has developed a tool called PAGER, standing for Prompt Assessment of Global Earthquakes for Response, that for every large earthquake around the globe, quickly determines the population exposed to different levels of shaking. This example map was produced within minutes of the 2018 magnitude 7.5 Palau, Indonesia earthquake. The colored lines are rapidly estimated isoseismal contours numbered with modified Mercalli intensities. The background grayscale map shows population density. The PAGER algorithm estimates that around 400,000 people experienced violent shaking of MMI 9. Another 400,000 experienced severe shaking of MMI 8. Around 147,000 very strong shaking of MMI 7, and so on. PAGER then takes these numbers and factoring in knowledge of the local building practices and economic development, quickly estimates the number of fatalities and the economic costs. This shows the initial PAGER estimates for the 2018 Palau earthquake. Within minutes of the earthquake occurring, the algorithm predicts that the number of fatalities most likely lies in the range 1,000 to 10,000, with a 20% chance of an even higher number. The final death toll for this earthquake, which took months to compile, was 4,340, in close agreement with the PAGER estimate. Unfortunately, in many parts of the world, when a large earthquake strikes, officials, first responders and journalists are unaware of the PAGER system. Because information from the very worst affected areas is slow to emerge, government and media alike often underestimate and under-report the impacts. For example, the Indonesian government initially reported that a few hundred people died in the Palau earthquake, rather than a few thousand. It took them three whole days even to request outside help for their search and rescue efforts. Unfortunately, since it's very unusual for people to survive more than three days in a collapsed building, this request came much too late. Unfortunately, this course of events is common in the most devastating earthquakes. For example, when the Italian town of L'Aquila was devastated by a magnitude 6.3 earthquake on 6th of April 2009, it was several hours before media outlets broadcast that there had been any deaths. The green line on this graph demonstrates how the reported death toll evolved over the coming several days. It was more than a day before even half of the true number of fatalities was recognised, and more than a week before the final death toll of 309 was determined. Note that this number lies within the range estimated by the USGS immediately after the earthquake struck, given by the pink bar. A similar story had unfolded almost a year before, on the 12th of May 2008, when a large area of western China was devastated by a magnitude 7.9 earthquake close to Wenchuan. For the first few days, coverage by the state-owned China News Service mentioned no more than a few thousand people missing or dead. In the end, the death toll was more than 87,000. Early predictive models estimated between 20,000 and 90,000 fatalities, in reasonable agreement with the final toll. And in March 2005, predictions were published of probable death tolls for hypothetical great earthquakes in the Himalayas. The fatality estimates were in the tens of thousands for each event. In October 2005, Kashmir's magnitude 7.9 earthquake was the largest in the world. In October 2005, Kashmir's magnitude 7.6 earthquake caused 86,000 deaths, the centre of the predicted range of 67,000 to 137,000. However, the BBC was still reporting only half that number of fatalities after 12 days. Remote sensing platforms, especially satellites, can also play a key role in gathering critical information in the aftermath of an earthquake that can help governments and first responders to target their efforts effectively. For example, these before and after satellite photographs reveal destruction to the waterfront area of the city of Palu following the 2018 earthquake and a tsunami that it triggered. These were available within hours of the earthquake. Here's an aerial photograph of the bridge that was destroyed in the centre of the satellite image. Here is another pair of before and after satellite images. The bridge in the previous photograph is on the right. What's interesting about this pair of photographs is that we can see the actual fault responsible for the earthquake. Look for it on the left of the image. The fault motion becomes obvious when the two images are toggled in quicker succession. You should be able to make out the lateral motion of a strike-slip fault. This still image zooms in on the earthquake surface rupture which crosses between the two red arrows. Observe that a number of once straight east-west streets are kinked at the fault. The offsets are clearly left lateral. This is a correlation map generated from the two photographs using a computer algorithm. Colours represent the amount by which pixels in the before photograph have to be shifted in order to match their location in the after photograph. Red colours indicate a shift to the north and yellow colours a shift to the south. One problem with satellite photographs is that they cannot penetrate cloud cover. What if the area impacted by the earthquake is cloudy in the days after the earthquake? This is where INSAR comes in, a satellite remote sensing technique we learned about when we were looking at the 2003 Bam earthquake in a previous lecture. INSAR stands for Interferometric Synthetic Aperture Radar and like all radar systems, it can be used to detect and detect and like all radar, uses radio waves which can penetrate cloud. The downside is that at present, INSAR satellites only pass over each location on the planet about every week and so if we are unlucky with the timing, the after radar image may not be available until a few days after the earthquake. This image is an INSAR correlation map of the Palau region in the 2018 earthquake. Pixels for which the backscattered radar signals of the before and after images match poorly are coloured red. Tragically, the main reason for the decorrelation in this instance is building collapse. Palau was simply devastated in this earthquake. Here we zoom in on downtown Palau. The level of detail is extraordinary. For example, note the band of red pixels crossing the mouth of the river. The INSAR imagery confirms collapse of the bridge shown earlier in this aerial photograph. Unfortunately, imagery of this kind was not used by the Indonesian authorities in their early response to the Palau earthquake but it is only a matter of time before techniques like this are used routinely to help authorities map out the worst damage and focus their search and rescue efforts. So watch out for much more of this in the future. This concludes our lecture on seismic risks.